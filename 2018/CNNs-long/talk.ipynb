{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks, Tensorflow, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Me: Adrin [adrin.info](http://adrin.info)\n",
    "\n",
    "\n",
    "### Ancud IT-Beratung [ancud.de](https://ancud.de)\n",
    "![ancud](figs/ancud.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Requirements: \n",
    "\n",
    " - python3\n",
    " - ipython\n",
    " - notebook (jupyter)\n",
    " - matplotlib\n",
    " - numpy, pandas\n",
    " - keras\n",
    " - tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A single neuron\n",
    "\n",
    "![spiking neural network](http://lis2.epfl.ch/CompletedResearchProjects/EvolutionOfAdaptiveSpikingCircuits/images/neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spiking Neural Networks\n",
    "\n",
    "![spiking system](http://lis2.epfl.ch/CompletedResearchProjects/EvolutionOfAdaptiveSpikingCircuits/images/spiking.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Artificial Neuron (Perceptron - 1957)\n",
    "[Source](http://natureofcode.com/book/chapter-10-neural-networks/)\n",
    "\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_05.png)\n",
    "\n",
    "$$output = f(x \\times w_x + y \\times w_y)$$\n",
    "$$f(x) = sign(x)$$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Signum_function.svg/200px-Signum_function.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Add bias\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_06.png)\n",
    "\n",
    "$$output = f(x \\times w_x + y \\times w_y + bias \\times w_{bias})$$\n",
    "$$f(x) = sign(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feed the data\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Excercise: derive the weight update formula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$output = sign(x \\times w_x + y \\times w_y + b \\times w_b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$error = desired - output$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$w_{new} = w + \\Delta w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\Delta w = error \\times input$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\Delta w =  error \\times input \\times \\text{learning rate}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### Logical OR\n",
    "\n",
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "\n",
    "def f(X, W):\n",
    "    return sign(sum([x * w for x, w in zip(X, W)]))\n",
    "\n",
    "data = np.array([[0, 0, 1],\n",
    "                 [1, 0, 1],\n",
    "                 [0, 1, 1],\n",
    "                 [1, 1, 1]])\n",
    "output = np.array([-1, 1, 1, 1])\n",
    "\n",
    "W = np.random.normal(0, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desired: -1, expected: -1, error:  0\n",
      "desired:  1, expected:  1, error:  0\n",
      "desired: -1, expected:  1, error:  2\n",
      "desired: -1, expected:  1, error:  2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print('desired: %2d, expected: %2d, error: %2d' % \n",
    "          (f(data[i], W), \n",
    "           output[i],\n",
    "           output[i] - f(data[i], W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def total_error(X, W, y):\n",
    "    return sum([abs(y[i] - f(X[i,], W)) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def new_w(X, W, y, learning_rate):\n",
    "    output = f(X, W)\n",
    "    error = y - output\n",
    "    delta_w = np.array([error * x * learning_rate for x in X])\n",
    "    return W + delta_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting error:  4\n",
      "error:  4, W: [ 2.30677987 -1.06664309  0.61521604]\n",
      "error:  2, W: [ 2.30677987 -0.06664309  0.61521604]\n",
      "error:  2, W: [2.30677987 0.93335691 0.61521604]\n",
      "error:  0, W: [ 2.30677987  0.93335691 -0.38478396]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "print('starting error: %2g' % total_error(data, W, output))\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,:], W, output[i], learning_rate)\n",
    "        \n",
    "    print('error: %2g, W: %s' % (total_error(data, W, output), str(W)))\n",
    "    if total_error(data, W, output) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Logical AND\n",
    "\n",
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[0, 0, 1],\n",
    "                 [1, 0, 1],\n",
    "                 [0, 1, 1],\n",
    "                 [1, 1, 1]])\n",
    "output = np.array([-1, -1, -1, 1])\n",
    "\n",
    "W = np.random.normal(0, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting error:  6\n",
      "error:  6, W: [-0.12756509  0.94978059  0.53770613]\n",
      "error:  4, W: [ 0.87243491  0.94978059 -0.46229387]\n",
      "error:  4, W: [ 0.87243491  1.94978059 -0.46229387]\n",
      "error:  2, W: [ 0.87243491  1.94978059 -1.46229387]\n",
      "error:  4, W: [ 1.87243491  1.94978059 -1.46229387]\n",
      "error:  0, W: [ 0.87243491  1.94978059 -2.46229387]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "print('starting error: %2g' % total_error(data, W, output))\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,:], W, output[i], learning_rate)\n",
    "        \n",
    "    print('error: %2g, W: %s' % (total_error(data, W, output), str(W)))\n",
    "    if total_error(data, W, output) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Demo\n",
    "http://natureofcode.com/book/chapter-10-neural-networks/\n",
    "\n",
    "https://bit.ly/1QwqTmA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Logical XOR\n",
    "\n",
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[0, 0, 1],\n",
    "                 [1, 0, 1],\n",
    "                 [0, 1, 1],\n",
    "                 [1, 1, 1]])\n",
    "output = np.array([-1, 1, 1, -1])\n",
    "\n",
    "W = np.random.normal(0, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting error:  4\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "print('starting error: %2g' % total_error(data, W, output))\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,:], W, output[i], learning_rate)\n",
    "        \n",
    "    print('error: %2g, W: %s' % (total_error(data, W, output), str(W)))\n",
    "    if total_error(data, W, output) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Train (observe more closely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting error:  4\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n",
      "error:  6, W: [-0.35259378 -0.47298198  0.18096587]\n",
      "error:  4, W: [-0.15259378 -0.47298198  0.38096587]\n",
      "error:  4, W: [-0.15259378 -0.27298198  0.58096587]\n",
      "error:  4, W: [-0.35259378 -0.47298198  0.38096587]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "print('starting error: %2g' % total_error(data, W, output))\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,:], W, output[i], learning_rate)\n",
    "        \n",
    "        print('error: %2g, W: %s' % (total_error(data, W, output), str(W)))\n",
    "    if total_error(data, W, output) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Separability\n",
    "\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_12.png)\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "#### Multilayer perceptron\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f046e9fa320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.random.randint(100, size=30)\n",
    "y = 10 * x - 40 + np.random.normal(size=30) * 40\n",
    "\n",
    "x = x.reshape(-1, 1)\n",
    "data = np.hstack((x, np.ones_like(x)))\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def f(X, W):\n",
    "    return sum([x * w for x, w in zip(X, W)])\n",
    "\n",
    "def new_w(X, W, y, learning_rate):\n",
    "    output = f(X, W)\n",
    "    error = y - output\n",
    "    delta_w = np.array([error * x * learning_rate for x in X])\n",
    "    return W + delta_w\n",
    "\n",
    "def total_error(X, W, y):\n",
    "    return sum([abs(y[i] - f(X[i,], W)) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 12668.9, W: [ 0.15565692 -0.33388966]\n",
      "error: 1132.35, W: [ 9.32385567 -3.39611448]\n",
      "error: 1126.58, W: [ 9.36432699 -6.07121385]\n",
      "error: 1121.75, W: [ 9.39818968 -8.30949269]\n",
      "error: 1117.71, W: [  9.4265229  -10.18227999]\n",
      "error: 1114.33, W: [  9.45022954 -11.74925737]\n",
      "error: 1112.4, W: [  9.4700651  -13.06036092]\n",
      "error: 1111.66, W: [  9.48666168 -14.15737263]\n",
      "error: 1111.04, W: [  9.50054818 -15.07525184]\n",
      "error: 1110.52, W: [  9.51216714 -15.84324933]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00001\n",
    "W = np.random.normal(size=2)\n",
    "\n",
    "for epoch in range(20000):\n",
    "    if epoch % 2000 == 0:\n",
    "        print('error: %2g, W: %s' % (total_error(data, W, y), str(W)))\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,], W, y[i], learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def plot(data, y, W):\n",
    "    plt.scatter(data[:,0], y)\n",
    "    plt.plot([0, 100], [f([0, 1], W), f([100, 1], W)])\n",
    "    plt.title('error: %2g, W: %s' % (total_error(data, W, y), str(W)))\n",
    "    plt.show()\n",
    "    \n",
    "learning_rate = 0.00001\n",
    "W = np.random.normal(size=2)\n",
    "\n",
    "for epoch in range(10):\n",
    "    clear_output()\n",
    "    plot(data, y, W)\n",
    "    time.sleep(1)\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,], W, y[i], learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dynamic Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 13202.1, W: [-0.21198259 -0.90185071], lr: 0.0001\n",
      "error: 1270.45, W: [  9.0033396 -18.3187657], lr: 9e-05\n",
      "error: 1225.57, W: [  9.11353097 -21.46810477], lr: 8.1e-05\n",
      "error: 1192.25, W: [  9.17965501 -21.99779733], lr: 7.29e-05\n",
      "error: 1162.36, W: [  9.2347146  -21.97840217], lr: 6.561e-05\n",
      "error: 1139.07, W: [  9.28425795 -21.83033219], lr: 5.9049e-05\n",
      "error: 1117.79, W: [  9.32897982 -21.65207252], lr: 5.31441e-05\n",
      "error: 1101.08, W: [  9.36883341 -21.47095735], lr: 4.78297e-05\n",
      "error: 1091.57, W: [  9.40381812 -21.29637669], lr: 4.30467e-05\n",
      "error: 1088.3, W: [  9.43410063 -21.13227384], lr: 3.8742e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "W = np.random.normal(size=2)\n",
    "\n",
    "for epoch in range(20000):\n",
    "    if epoch % 2000 == 0:\n",
    "        print('error: %2g, W: %s, lr: %4g' % (total_error(data, W, y), str(W), learning_rate))\n",
    "        learning_rate = learning_rate * 0.9\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        W = new_w(data[i,], W, y[i], learning_rate)\n",
    "        \n",
    "    if total_error(data, W, y) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative Approach\n",
    "![](./figs/iterative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/loss1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/loss2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/loss3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/loss4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/lr1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/lr2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](figs/lr3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Playground\n",
    "https://developers.google.com/machine-learning/crash-course/reducing-loss/playground-exercise\n",
    "\n",
    "https://bit.ly/2vmmqUX\n",
    "\n",
    "![](figs/pl0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Architectures\n",
    "\n",
    "### Feedforward\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/560px-Artificial_neural_network.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Activation Functions: [wiki](https://en.wikipedia.org/wiki/Activation_function)\n",
    "https://en.wikipedia.org/wiki/Activation_function\n",
    "\n",
    "![](./figs/activation-funcs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Playground\n",
    "\n",
    "https://bit.ly/2ETsjsc\n",
    "\n",
    "![](figs/playground.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/79/Recurrent_ann_dependency_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Elman SRNN\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/8f/Elman_srnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unsupervised, eg. SOM\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Somtraining.svg/1000px-Somtraining.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## New developments\n",
    "\n",
    "### General-purpose computing on graphics processing units (GPGPU)\n",
    "\n",
    "#### GPU vs CPU\n",
    "![](http://www.frontiersin.org/files/Articles/70265/fgene-04-00266-HTML/image_m/fgene-04-00266-g001.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2005\n",
    "![](figs/gpgpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Better algorithms\n",
    "\n",
    "#### 2011\n",
    "![](figs/2011-conv-mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Convolutional Neural Networks (CNN)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n",
    "\n",
    "### Weight Sharing, Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Max Pooling\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
    "\n",
    "### Dropout, {L1, L2} regularization, artificial data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NN Libraries\n",
    "\n",
    "![](figs/nn-libs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Keras\n",
    "#### keras.io\n",
    "\n",
    "![](figs/keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MNIST\n",
    "\n",
    "![](http://andrea.burattin.net/public-files/stuff/handwritten-digit-recognition/example_mnist.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MNIST\n",
    "\n",
    "![](figs/mnist-perfs.png)\n",
    "\n",
    "### Based on keras examples, specifically [this one](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Keras\n",
    "https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "https://bit.ly/2HzzSKp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Good old scikit-learn & linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('variance filter', VarianceThreshold(threshold=0.01)),\n",
    "    ('standard_scale', StandardScaler()),\n",
    "    ('estimator', Lasso(alpha=0.1, max_iter=2000)),\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train.reshape(60000, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47789595238095106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "label_ranking_average_precision_score(y_test, pipeline.predict(x_test.reshape(len(x_test), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99532500000000002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ranking_average_precision_score(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorFlow\n",
    "\n",
    "![](figs/tf-layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TensorFlow\n",
    "\n",
    "![](figs/tf-layers2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tensorboard\n",
    "    tensorboard --logdir=path/to/log-directory\n",
    "    \n",
    "![](figs/tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Intro\n",
    "\n",
    "- building the graph vs computing the graph\n",
    "- inputs/constants/variables\n",
    "- gradients and training\n",
    "\n",
    "#### Tutorial (up to tf.contrib.learn)\n",
    "https://www.tensorflow.org/versions/r1.1/get_started/get_started#the_computational_graph\n",
    "\n",
    "https://bit.ly/2HsDf5A\n",
    "\n",
    "### Tensorboard\n",
    "    tensorboard --logdir=path/to/log-directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MNIST with TF\n",
    "\n",
    "- First tutorial:\n",
    "  - https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "  - https://bit.ly/2H83QBG\n",
    "- Second Tutorial:\n",
    "  - https://www.tensorflow.org/versions/r1.1/get_started/mnist/pros\n",
    "  - https://bit.ly/2JQUOe5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolution Kernels\n",
    "![](figs/convolution-kernels.png)\n",
    "[Source](https://www.jebruner.com/2017/07/interpreting-and-fooling-convolutional-neural-networks-part-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpret CNNs\n",
    "\n",
    "![](figs/cnn1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpret CNNs\n",
    "\n",
    "![](figs/cnn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpret CNNs\n",
    "\n",
    "![](figs/cnn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpret CNNs\n",
    "\n",
    "![](figs/cnn4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpret CNNs\n",
    "\n",
    "![](figs/cnn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How convolutional neural networks see the world\n",
    "\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n",
    "\n",
    "https://bit.ly/2oLWXx3\n",
    "\n",
    "![](figs/cnn-interpret.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "![](figs/normal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding classes\n",
    "\n",
    "![](figs/added-nodes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dimentionality reduction / Transfer learning\n",
    "\n",
    "![](figs/dimentionality-reduction.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dimentionality reduction / Transfer learning\n",
    "\n",
    "![](figs/dimentionality-reduction-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### High level APIs\n",
    "\n",
    "#### tf.keras\n",
    "\n",
    "![](figs/tf-keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### High level APIs\n",
    "\n",
    "#### tf.estimator\n",
    "\n",
    "![](figs/tf-estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "    def train_input_fn(features, labels, batch_size):\n",
    "        \"\"\"An input function for training\"\"\"\n",
    "        # Convert the inputs to a Dataset.\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "        # Shuffle, repeat, and batch the examples.\n",
    "        dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "        # Return the read end of the pipeline.\n",
    "        return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def my_model_fn(\n",
    "   features, # This is batch_features from input_fn\n",
    "   labels,   # This is batch_labels from input_fn\n",
    "   mode,     # An instance of tf.estimator.ModeKeys\n",
    "   params):  # Additional configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        'hidden_units': [10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        'n_classes': 3,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Complete Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"An Example of a custom Estimator for the Iris dataset.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import iris_data\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
    "parser.add_argument('--train_steps', default=1000, type=int,\n",
    "                    help='number of training steps')\n",
    "\n",
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
    "    # Create three fully connected layers each layer having a dropout\n",
    "    # probability of 0.1.\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    args = parser.parse_args(argv[1:])\n",
    "\n",
    "    # Fetch the data\n",
    "    (train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "\n",
    "    # Feature columns describe how to use the input.\n",
    "    my_feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model,\n",
    "        params={\n",
    "            'feature_columns': my_feature_columns,\n",
    "            # Two hidden layers of 10 nodes each.\n",
    "            'hidden_units': [10, 10],\n",
    "            # The model must choose between 3 classes.\n",
    "            'n_classes': 3,\n",
    "        })\n",
    "\n",
    "    # Train the Model.\n",
    "    classifier.train(\n",
    "        input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n",
    "        steps=args.train_steps)\n",
    "\n",
    "    # Evaluate the model.\n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))\n",
    "\n",
    "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "\n",
    "    # Generate predictions from the model\n",
    "    expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "    predict_x = {\n",
    "        'SepalLength': [5.1, 5.9, 6.9],\n",
    "        'SepalWidth': [3.3, 3.0, 3.1],\n",
    "        'PetalLength': [1.7, 4.2, 5.4],\n",
    "        'PetalWidth': [0.5, 1.5, 2.1],\n",
    "    }\n",
    "\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                                labels=None,\n",
    "                                                batch_size=args.batch_size))\n",
    "\n",
    "    for pred_dict, expec in zip(predictions, expected):\n",
    "        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "        print(template.format(iris_data.SPECIES[class_id],\n",
    "                              100 * probability, expec))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tutorial\n",
    "\n",
    "- https://www.tensorflow.org/get_started/custom_estimators\n",
    "- https://bit.ly/2HIq7qJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The real deal\n",
    "\n",
    "https://www.tensorflow.org/tutorials/layers\n",
    "\n",
    "https://bit.ly/2HcRcVV\n",
    "\n",
    "![](figs/real-deal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inception-V3\n",
    "\n",
    "https://arxiv.org/pdf/1512.00567.pdf\n",
    "\n",
    "https://bit.ly/2uWBuHs\n",
    "\n",
    "![](figs/inception-v3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pixelwise Segmentation\n",
    "\n",
    "![](figs/pixelwise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pixelwise Segmentation\n",
    "#### DeepLab-v3+\n",
    "\n",
    "![](figs/deeplab-v3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Links\n",
    "\n",
    "- General Intro\n",
    "  - https://arxiv.org/pdf/1404.7828.pdf\n",
    "- Convolutions\n",
    "  - https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n",
    "  - https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\n",
    "- CNNs\n",
    "  - https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "- Good old LSTM paper\n",
    "  - http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\n",
    "- Advanced Tutorials\n",
    "  - https://www.tensorflow.org/tutorials/layers\n",
    "  -https://bit.ly/2HcRcVV\n",
    "- Inception Paper (included in the tutorials)\n",
    "  - https://arxiv.org/pdf/1512.00567.pdf\n",
    "  - https://github.com/tensorflow/models/blob/master/research/inception/inception/slim/inception_model.py\n",
    "- Pixelwise Segmentation (DeepLab-v3+)\n",
    "  - Blog post\n",
    "    - https://research.googleblog.com/2018/03/semantic-image-segmentation-with.html\n",
    "    - https://bit.ly/2JTrjrY\n",
    "  - Repository\n",
    "    - https://github.com/tensorflow/models/tree/master/research/deeplab\n",
    "    - https://bit.ly/2GClDkT\n",
    "  - Other\n",
    "    - https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "    - https://research.googleblog.com/2018/03/mobile-real-time-video-segmentation.html\n",
    "- AutoML related\n",
    "  - https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\n",
    "- Transfer Learning\n",
    "  - https://github.com/MorvanZhou/Tensorflow-Tutorial/blob/master/tutorial-contents/407_transfer_learning.py\n",
    "  - http://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final remarks\n",
    "\n",
    " - Usecases with not enough data\n",
    " - Usecases with many small models\n",
    " - Gain on performance vs. cost\n",
    " - Network architecture & hyperparameters\n",
    " - Deployment\n",
    "   - Cleanup\n",
    "   - Batching\n",
    "   - Serving"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
