{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to write a scikit-learn compatible estimator\n",
    "\n",
    "## Adrin Jalali\n",
    "### @adrinjalali, scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to scikit-learn\n",
    "\n",
    "A machine learning library implementing statistical machine learning methods.\n",
    "\n",
    "__Out of scope:__\n",
    "- Neural Networks (except a simple MLP implementation)\n",
    "- GPU\n",
    "\n",
    "__Important components in the API:__\n",
    "\n",
    "- estimators (transformers and predictors)\n",
    "- scorers\n",
    "- meta-estimators\n",
    "    - pipeline\n",
    "    - grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# A common workflow includes a pipeline once the data is loaded.\n",
    "# We usually preprocess the data and prepare it for the\n",
    "# final classifier or regressor.\n",
    "# We call each step an \"estimator\", the preprocessing steps which\n",
    "# augment the data \"transformers\", and the final step a classifier\n",
    "# or a regressor.\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# Each step can be tuned with many hyper-parameters, and we want to\n",
    "# find the best hyper-parameter set for the given dataset.\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier, we use a grid search.\n",
    "grid_search = GridSearchCV(pipeline, parameters)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why a custom estimator?\n",
    "\n",
    "- scikit-learn doesn't include all algorithms, and it has a very high bar for including one. You can test your new or modified algorithm as a custom estimator.\n",
    "- The library does not include methods which are appropriate only for a small set o use-cases, and if you happen to work on one of those problems, you might need to develop your own estimator to tackle the specific issues you have.\n",
    "- You may want to add some steps before or after running each step, in which case you can write a meta-estimator wrapping around the steps you usually would have in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic API\n",
    "\n",
    "- `fit (X, y, **kwargs)`\n",
    "- `predict(X)` (`predict_proba` and `decision_function`)\n",
    "- `transform(X)`\n",
    "- `score(X, y[, sample_weight])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import (\n",
    "    check_array, check_is_fitted, check_X_y)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "class MyTransformer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model_ = spacy.load(\"en_core_web_md\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        check_is_fitted(self)\n",
    "        docs = self.model_.pipe(X)\n",
    "        return np.array(map(lambda x: x.vector, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6863d0a6f1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBeseEstimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BeseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class MyClassifier(ClassifierMixin, BeseEstimator):\n",
    "    def __init__(self, C=1.0, random_state=0):\n",
    "        self.C = C\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.estimator_ = LogisticRegression(C=self.C,\n",
    "                                             random_state=self.random_state)\n",
    "        self.classes_ = self.estimator_.classes_\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_classes=3, n_informative=3, random_state=0)\n",
    "probs = LogisticRegression(random_state=0).fit(X, y).predict_proba(X[:3])\n",
    "res = np.argmax(probs, axis=1)\n",
    "mask = np.max(probs, axis=1) < .9\n",
    "res[~mask] = -1\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def check_is_fitted(estimator, attributes=None, msg=None, all_or_any=all):\n",
    "    \"\"\"Perform is_fitted validation for estimator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "def check_array(array, accept_sparse=False, accept_large_sparse=True,\n",
    "                dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n",
    "                ensure_2d=True, allow_nd=False, ensure_min_samples=1,\n",
    "                ensure_min_features=1, estimator=None):\n",
    "\n",
    "    \"\"\"Input validation on an array, list, sparse matrix or similar.\n",
    "\n",
    "    By default, the input is checked to be a non-empty 2D array containing\n",
    "    only finite values. If the dtype of the array is object, attempt\n",
    "    converting to float, raising on failure.\n",
    "    \"\"\"\n",
    "    \n",
    "def check_X_y(X, y, accept_sparse=False, accept_large_sparse=True,\n",
    "              dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n",
    "              ensure_2d=True, allow_nd=False, multi_output=False,\n",
    "              ensure_min_samples=1, ensure_min_features=1, y_numeric=False,\n",
    "              estimator=None):\n",
    "    \"\"\"Input validation for standard estimators.\n",
    "\n",
    "    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n",
    "    default, X is checked to be non-empty and containing only finite values.\n",
    "    Standard input checks are also applied to y, such as checking that y\n",
    "    does not have np.nan or np.inf targets. For multi-label y, set\n",
    "    multi_output=True to allow 2D and sparse y. If the dtype of X is\n",
    "    object, attempt converting to float, raising on failure.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Common Tests on Our Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import parametrize_with_checks\n",
    "\n",
    "@parametrize_with_checks([MyClassifier])\n",
    "def test_sklearn_compatible_estimator(estimator, check):\n",
    "    check(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================ test session starts ============================================================================\n",
      "platform linux -- Python 3.8.1, pytest-5.3.3, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /home/adrin/Documents/talks/sklearn-estimator-fosdem-2020\n",
      "collected 40 items\n",
      "\n",
      "custom_estimators.py ........................................                                                                                                         [100%]\n",
      "\n",
      "============================================================================ 40 passed in 0.24s =============================================================================\n"
     ]
    }
   ],
   "source": [
    "import ipytest\n",
    "ipytest.config(rewrite_asserts=True, magics=True)\n",
    "__file__ = 'custom_estimators.ipynb'\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-31 16:56:06,382 C: 1\n",
      "2020-01-31 16:56:06,382 fitting on 750 samples\n",
      "2020-01-31 16:56:06,397 fit end/\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_informative=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf = MyClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-31 16:56:06,405 predicting on 250 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.916"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-31 16:56:06,432 C: 0.1\n",
      "2020-01-31 16:56:06,432 fitting on 750 samples\n",
      "2020-01-31 16:56:06,443 fit end/\n",
      "2020-01-31 16:56:06,445 predicting on 250 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "pipe = make_pipeline(SelectKBest(k=2), MyClassifier(C=.1))\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline in a Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "param_grid = {'selectkbest__k': [1, 2, 5, 10, 20],\n",
    "              'myclassifier__C': [0.1, 1, 100]}\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid).fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('selectkbest',\n",
       "                 SelectKBest(k=20,\n",
       "                             score_func=<function f_classif at 0x7f3e9f5e0280>)),\n",
       "                ('myclassifier', MyClassifier(C=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventions\n",
    "\n",
    "- `fit` should only get sample aligned data in `fit_params`\n",
    "    - everything else should go through `__init__`\n",
    "- `__init__` doesn't set anything other than the parameters passed to it\n",
    "- `obj.attr` is set through `__init__` and `set_params`\n",
    "- `obj.attr_` is set during fit and counts as public API\n",
    "- `obj._attr` is private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Tags\n",
    "\n",
    "``` python\n",
    "_DEFAULT_TAGS = {\n",
    "    'non_deterministic': False,\n",
    "    'requires_positive_X': False,\n",
    "    'requires_positive_y': False,\n",
    "    'X_types': ['2darray'],\n",
    "    'poor_score': False,\n",
    "    'no_validation': False,\n",
    "    'multioutput': False,\n",
    "    \"allow_nan\": False,\n",
    "    'stateless': False,\n",
    "    'multilabel': False,\n",
    "    '_skip_test': False,\n",
    "    'multioutput_only': False,\n",
    "    'binary_only': False,\n",
    "    'requires_fit': True}\n",
    "```\n",
    "\n",
    "You can change them with:\n",
    "\n",
    "``` python\n",
    "class MyMultiOutputEstimator(BaseEstimator):\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'multioutput_only': True,\n",
    "                'non_deterministic': True}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upcoming Features\n",
    "\n",
    "- `n_features_in_`[#16112](https://github.com/scikit-learn/scikit-learn/pull/16112), `n_features_out_`[#14241](https://github.com/scikit-learn/scikit-learn/pull/14241)\n",
    "- `feature_names_in_`, `feature_names_out_` [SLEP#7](https://github.com/scikit-learn/enhancement_proposals/pull/17), [SLEP#8](https://github.com/scikit-learn/enhancement_proposals/pull/18), [SLEP#12](https://github.com/scikit-learn/enhancement_proposals/pull/25)\n",
    "- sample/feature/data properties (through `_request_props`?) [SLEP#6](https://github.com/scikit-learn/enhancement_proposals/pull/16), [#16079](https://github.com/scikit-learn/scikit-learn/pull/16079)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Details/Further Reading\n",
    "\n",
    "- [https://scikit-learn.org/dev/developers/develop.html](https://scikit-learn.org/stable/developers/develop.html)\n",
    "- `sklearn/base.py`\n",
    "- `sklearn/metaestimators.py`\n",
    "- `sklearn/utils/validation.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?\n",
    "### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
