{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to write a scikit-learn compatible estimator\n",
    "\n",
    "## Adrin Jalali\n",
    "### @adrinjalali, scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important components in the API:__\n",
    "\n",
    "- estimators (transformers and predictors)\n",
    "- metrics and scorers\n",
    "- meta-estimators\n",
    "    - pipeline\n",
    "    - grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# A common workflow includes a pipeline once the data is loaded.\n",
    "# We usually preprocess the data and prepare it for the\n",
    "# final classifier or regressor.\n",
    "# We call each step an \"estimator\", the preprocessing steps which\n",
    "# augment the data \"transformers\", and the final step a classifier\n",
    "# or a regressor.\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# Each step can be tuned with many hyper-parameters, and we want to\n",
    "# find the best hyper-parameter set for the given dataset.\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier, we use a grid search.\n",
    "grid_search = GridSearchCV(pipeline, parameters)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why a custom estimator?\n",
    "\n",
    "- scikit-learn doesn't include all algorithms, and it has a very high bar for including one. You can test your new or modified algorithm as a custom estimator.\n",
    "- The library does not include methods which are appropriate only for a small set o use-cases, and if you happen to work on one of those problems, you might need to develop your own estimator to tackle the specific issues you have.\n",
    "- You may want to add some steps before or after running each step, in which case you can write a meta-estimator wrapping around the steps you usually would have in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - True Story!\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5813333333333334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# need to run: python -m spacy download en_core_web_md\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_20newsgroups(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:500], y[:500])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = list(nlp.pipe(X_train))\n",
    "feature_matrix = np.array(list(map(lambda x: x.vector, docs)))\n",
    "\n",
    "clf = SGDClassifier().fit(feature_matrix, y_train)\n",
    "clf.score(feature_matrix, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.184"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = list(nlp.pipe(X_test))\n",
    "feature_matrix_test = np.array(list(map(lambda x: x.vector, docs)))\n",
    "clf.score(feature_matrix_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment and backend\n",
    "\n",
    "If the model is being _deployed_ in a backend, the backend would need to know how to process the data and how to run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic API\n",
    "\n",
    "- `fit (X, y, **kwargs)`\n",
    "- `predict(X)` (`predict_proba` and `decision_function`)\n",
    "- `transform(X)`\n",
    "- `score(X, y[, sample_weight])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class SpacyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, langulage_model='en_core_web_sm'):\n",
    "        self.language_model = language_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.nlp_ = spacy.load(self.language_model)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self)\n",
    "        try:\n",
    "            docs = list(self.nlp_.pipe(X))\n",
    "        except OSError:\n",
    "            # This is needed when the language model is not pickled with the transformer itself\n",
    "            self.nlp_ = spacy.load(\"en_core_web_md\")\n",
    "            docs = list(self.nlp_.pipe(X))\n",
    "\n",
    "        feature_matrix = np.array(list(map(lambda x: x.vector, docs)))\n",
    "        return feature_matrix\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'X_types': ['string']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def check_is_fitted(estimator, attributes=None, msg=None, all_or_any=all):\n",
    "    \"\"\"Perform is_fitted validation for estimator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "def check_array(array, accept_sparse=False, accept_large_sparse=True,\n",
    "                dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n",
    "                ensure_2d=True, allow_nd=False, ensure_min_samples=1,\n",
    "                ensure_min_features=1, estimator=None):\n",
    "\n",
    "    \"\"\"Input validation on an array, list, sparse matrix or similar.\n",
    "\n",
    "    By default, the input is checked to be a non-empty 2D array containing\n",
    "    only finite values. If the dtype of the array is object, attempt\n",
    "    converting to float, raising on failure.\n",
    "    \"\"\"\n",
    "    \n",
    "def check_X_y(X, y, accept_sparse=False, accept_large_sparse=True,\n",
    "              dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n",
    "              ensure_2d=True, allow_nd=False, multi_output=False,\n",
    "              ensure_min_samples=1, ensure_min_features=1, y_numeric=False,\n",
    "              estimator=None):\n",
    "    \"\"\"Input validation for standard estimators.\n",
    "\n",
    "    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n",
    "    default, X is checked to be non-empty and containing only finite values.\n",
    "    Standard input checks are also applied to y, such as checking that y\n",
    "    does not have np.nan or np.inf targets. For multi-label y, set\n",
    "    multi_output=True to allow 2D and sparse y. If the dtype of X is\n",
    "    object, attempt converting to float, raising on failure.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Common Tests on Our Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import parametrize_with_checks\n",
    "\n",
    "@parametrize_with_checks([SpacyTransformer()])\n",
    "def test_sklearn_compatible_estimator(estimator, check):\n",
    "    check(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================= test session starts ==================================================================================\n",
      "platform linux -- Python 3.8.1, pytest-5.3.3, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /home/adrin/Documents/talks/sklearn-estimator-spacy\n",
      "collected 1 item\n",
      "\n",
      "custom_estimators.py s                                                                                                                                                           [100%]\n",
      "\n",
      "=================================================================================== warnings summary ===================================================================================\n",
      "/home/adrin/miniconda3/envs/talks/lib/python3.8/site-packages/sklearn/utils/estimator_checks.py:234\n",
      "  /home/adrin/miniconda3/envs/talks/lib/python3.8/site-packages/sklearn/utils/estimator_checks.py:234: SkipTestWarning: Can't test estimator SpacyTransformer which requires input  of type ['string']\n",
      "    warnings.warn(\"Can't test estimator {} which requires input \"\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "============================================================================ 1 skipped, 1 warning in 0.03s =============================================================================\n"
     ]
    }
   ],
   "source": [
    "import ipytest\n",
    "ipytest.config(rewrite_asserts=True, magics=True)\n",
    "__file__ = 'custom_estimators.ipynb'\n",
    "\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45556316,  0.17772849, -0.96406066, ...,  0.60679364,\n",
       "         0.72729415,  0.5039766 ],\n",
       "       [ 0.23949091, -0.09925516, -0.97056216, ...,  0.578748  ,\n",
       "         0.3359907 ,  0.43843523],\n",
       "       [ 0.46740833,  0.8174765 , -1.347426  , ...,  0.6512799 ,\n",
       "         0.33042884,  0.7753896 ],\n",
       "       ...,\n",
       "       [ 0.31319967, -0.34968168, -1.3392841 , ...,  0.2398599 ,\n",
       "         0.46239212,  0.4577189 ],\n",
       "       [ 0.4845453 ,  0.23500457, -0.88941014, ...,  0.5740574 ,\n",
       "         0.23149489,  0.663821  ],\n",
       "       [ 0.40018892,  0.3793777 , -1.191784  , ...,  0.7832488 ,\n",
       "         0.00516417,  0.70668983]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpacyTransformer().fit().transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.152"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = make_pipeline(SpacyTransformer(), SGDClassifier())\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline in a Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.168"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'sgdclassifier__penalty': ['l1', 'l2'],\n",
    "              'sgdclassifier__alpha': [0.0001, 0.001]}\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, n_jobs=6, verbose=1).fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('spacytransformer', SpacyTransformer()),\n",
       "                ('sgdclassifier', SGDClassifier(penalty='l1'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.set_params(n_jobs=4)\n",
    "gs.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventions\n",
    "\n",
    "- `fit` should only get sample aligned data in `fit_params`\n",
    "    - everything else should go through `__init__`\n",
    "- `__init__` doesn't set anything other than the parameters passed to it\n",
    "- `obj.attr` is set through `__init__` and `set_params`\n",
    "- `obj.attr_` is set during fit and counts as public API\n",
    "- `obj._attr` is private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Tags\n",
    "\n",
    "``` python\n",
    "_DEFAULT_TAGS = {\n",
    "    'non_deterministic': False,\n",
    "    'requires_positive_X': False,\n",
    "    'requires_positive_y': False,\n",
    "    'X_types': ['2darray'],\n",
    "    'poor_score': False,\n",
    "    'no_validation': False,\n",
    "    'multioutput': False,\n",
    "    \"allow_nan\": False,\n",
    "    'stateless': False,\n",
    "    'multilabel': False,\n",
    "    '_skip_test': False,\n",
    "    'multioutput_only': False,\n",
    "    'binary_only': False,\n",
    "    'requires_fit': True}\n",
    "```\n",
    "\n",
    "You can change them with:\n",
    "\n",
    "``` python\n",
    "class MyMultiOutputEstimator(BaseEstimator):\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'multioutput_only': True,\n",
    "                'non_deterministic': True}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upcoming Features\n",
    "\n",
    "- `n_features_in_`[#16112](https://github.com/scikit-learn/scikit-learn/pull/16112), `n_features_out_`[#14241](https://github.com/scikit-learn/scikit-learn/pull/14241)\n",
    "- `feature_names_in_`, `feature_names_out_` [SLEP#7](https://github.com/scikit-learn/enhancement_proposals/pull/17), [SLEP#8](https://github.com/scikit-learn/enhancement_proposals/pull/18), [SLEP#12](https://github.com/scikit-learn/enhancement_proposals/pull/25)\n",
    "- sample/feature/data properties (through `_request_props`?) [SLEP#6](https://github.com/scikit-learn/enhancement_proposals/pull/16), [#16079](https://github.com/scikit-learn/scikit-learn/pull/16079)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Details/Further Reading\n",
    "\n",
    "- [https://scikit-learn.org/dev/developers/develop.html](https://scikit-learn.org/stable/developers/develop.html)\n",
    "- `sklearn/base.py`\n",
    "- `sklearn/metaestimators.py`\n",
    "- `sklearn/utils/validation.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?\n",
    "### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
